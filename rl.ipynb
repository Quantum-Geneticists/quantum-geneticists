{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy import integrate\n",
    "from scipy import sparse\n",
    "import scipy.optimize as optimize\n",
    "import qutip as qt\n",
    "import os\n",
    "#from EDAspy.optimization import UMDAd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define functions for spin operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping operator specifications to the corresponding operator functions\n",
    "opstr2fun = {'x': lambda dim: qt.spin_Jx((dim-1)/2),\n",
    "             'y': lambda dim: qt.spin_Jy((dim-1)/2),\n",
    "             'z': lambda dim: qt.spin_Jz((dim-1)/2),\n",
    "             'p': lambda dim: qt.spin_Jp((dim-1)/2),\n",
    "             'm': lambda dim: qt.spin_Jm((dim-1)/2),\n",
    "             'i': qt.identity}\n",
    "\n",
    "def mkSpinOp(dims, specs):\n",
    "    \"\"\"Returns a tensor product of operators based on given dimensions and specifications.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : list of int\n",
    "        List of dimensions of individual operators.\n",
    "    specs :\n",
    "        List of index-specification pairs indicating which operator to modify and how.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    qobj\n",
    "        The matrix (tensor product of individual operators).\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> spin_op = mkSpinOp([3, 4, 2], [(0, 'x'), (1, 'y'), (2, 'z')])\n",
    "    >>> spin_op\n",
    "    [[3, 4, 2], [3, 4, 2]]\n",
    "    \"\"\"\n",
    "\n",
    "    ops = [qt.identity(d) for d in dims]\n",
    "    for ind, opstr in specs:\n",
    "        ops[ind] = ops[ind] * opstr2fun[opstr](dims[ind])\n",
    "    return qt.tensor(ops)\n",
    "\n",
    "def idOp(dims):\n",
    "    \"\"\"Returns the tensor product of identity operators with given dimensions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : list of int\n",
    "        List of dimensions of individual operators.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    qobj\n",
    "        The identity matrix (tensor product of individual operators).\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> id_op = idOp([3, 4, 2])\n",
    "    >>> id_op.dims\n",
    "    [[3, 4, 2], [3, 4, 2]]\n",
    "    \"\"\"\n",
    "\n",
    "    return mkSpinOp(dims, [])\n",
    "\n",
    "def zeroOp(dims):\n",
    "    \"\"\"Returns the tensor product of zero operators with given dimensions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : list of int\n",
    "        List of dimensions of individual operators.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    qobj\n",
    "        The zero matrix (tensor product of individual operators).\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> zero_op = zeroOp([3, 4, 2])\n",
    "    >>> zero_op.dims\n",
    "    [[3, 4, 2], [3, 4, 2]]\n",
    "    \"\"\"\n",
    "\n",
    "    d = np.prod(dims)\n",
    "    return qt.Qobj(sparse.csr_matrix((d, d), dtype=np.float64), \n",
    "                       dims=[list(dims)]*2, type=\"oper\", isherm=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define functions for Hamiltonian operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkH1(dims, ind, parvec):\n",
    "    \"\"\"Returns the Hamiltonian operator based on the given dimensions, index, and parameter vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : list of int\n",
    "        List of dimensions of individual operators.\n",
    "    ind : int\n",
    "        Index indicating which operator to modify.\n",
    "    parvec : list of float\n",
    "        List of parameter values for each spin component. (???)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    qutip.qobj\n",
    "        The Hamiltonian operator.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> H1 = mkH1([3, 4, 2], 1, [1.0, 0.5, 0.1])\n",
    "    >>> H1.dims\n",
    "    [[3, 4, 2], [3, 4, 2]]\n",
    "    \"\"\"\n",
    "\n",
    "    axes = ['x', 'y', 'z']\n",
    "    components = [v * mkSpinOp(dims, [(ind,ax)]) for v, ax in zip(parvec, axes) if v!=0]\n",
    "    if components:\n",
    "        return sum(components)\n",
    "    else:\n",
    "        return zeroOp(dims)\n",
    "\n",
    "def mkH12(dims, ind1, ind2, parmat):\n",
    "    \"\"\"Returns the Hamiltonian operator based on the given dimensions, indices, and parameter matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dims : list of int\n",
    "        List of dimensions of individual operators.\n",
    "    ind1 : int\n",
    "        Index indicating the first operator to modify.\n",
    "    ind2 : int\n",
    "        Index indicating the second operator to modify.\n",
    "    parmat : np.ndarray\n",
    "        Parameter matrix specifying the coupling strengths. (???)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    qutip.qobj\n",
    "        The Hamiltonian operator.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> H12 = mkH12([3, 4, 2], 0, 1, np.array([[1.0, 0.5, -0.3], [0.5, 0.0, 0.2], [-0.3, 0.2, 0.7]]))\n",
    "    >>> H12.dims\n",
    "    [[3, 4, 2], [3, 4, 2]]\n",
    "    \"\"\"\n",
    "    \n",
    "    axes = ['x', 'y', 'z']\n",
    "    components = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if parmat[i,j] != 0:\n",
    "                components.append(parmat[i,j] * mkSpinOp(dims, [(ind1,axes[i]), (ind2,axes[j])]))\n",
    "    if components:\n",
    "        return sum(components)\n",
    "    else:\n",
    "        return zeroOp(dims)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define function for the dense of an operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(op):\n",
    "    \"\"\"Returns the dense array representation of the given operator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    op : Union[qutip.qobj.Qobj, scipy.sparse.csc_matrix]\n",
    "        The input operator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The dense array representation of the operator.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> operator = qt.Qobj([[1, 2], [3, 4]])\n",
    "    \n",
    "    # Get the dense array representation of the operator\n",
    "    >>> dense_op = dense(operator)\n",
    "    array([[1.+0.j, 2.+0.j], \n",
    "        [3.+0.j, 4.+0.j]])\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(op) is qt.qobj.Qobj:\n",
    "        return np.asarray(op.data.todense())\n",
    "    else:\n",
    "        return np.asarray(op.todense())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Trace}({\\rho(t) Z})\n",
    "$$\n",
    "\n",
    "for \n",
    "\n",
    "$$\n",
    "\\rho(t) = U(t)\\rho(0) U^{\\dagger}(t)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define functions for computing expectation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expvalsConstH(Heff, rho0, ops, dt, nr_steps):\n",
    "    \"\"\"Returns the expectation values of operators and the final density matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Heff : numpy.ndarray\n",
    "        The effective Hamiltonian.\n",
    "    rho0 : numpy.ndarray\n",
    "        The initial density matrix.\n",
    "    ops : list of numpy.ndarray\n",
    "        List of operators for which expectation values are computed.\n",
    "    dt : float\n",
    "        The time step size.\n",
    "    nr_steps : int\n",
    "        The number of steps in the evolution.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    obs : numpy.ndarray\n",
    "        The expectation values of the operators over time.\n",
    "    rhot : numpy.ndarray\n",
    "        The final density matrix.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> Heff = np.array([[1, 0], [0, -1]])\n",
    "    >>> rho0 = np.array([[1, 0], [0, 0]])\n",
    "    >>> ops = [np.array([[1, 0], [0, 1]]), np.array([[0, 1], [1, 0]])]\n",
    "    >>> dt = 0.1\n",
    "    >>> nr_steps = 10\n",
    "\n",
    "    # Compute the expectation values and final density matrix\n",
    "    >>> obs, rhot = expvalsConstH(Heff, rho0, ops, dt, nr_steps)\n",
    "    >>> obs\n",
    "    array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
    "    >>> rhot\n",
    "    array([[1.+0.j, 0.+0.j],\n",
    "       [0.+0.j, 0.+0.j]])\n",
    "    \"\"\"\n",
    "\n",
    "    obs = np.zeros((len(ops),nr_steps))\n",
    "    rhot = rho0\n",
    "    U = linalg.expm(-1j*dt*Heff)\n",
    "    for i in range(nr_steps):\n",
    "        rhot = U @ rhot @ U.T.conjugate()\n",
    "        for s in range(len(ops)):\n",
    "            obs[s,i] = np.real(np.trace(ops[s] @ rhot))\n",
    "                \n",
    "    return obs, rhot\n",
    "\n",
    "def expvalsPiecewiseConstHt(H0, H1, u, rho0, ops, dt):\n",
    "    \"\"\"Returns the expectation values of operators and the final density matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H0 : numpy.ndarray\n",
    "        The initial fixed Hamiltonian.\n",
    "    H1 : numpy.ndarray\n",
    "        The drift (control) time-dependent Hamiltonian.\n",
    "    u : numpy.ndarray\n",
    "        The magnetic field (dependent variable).\n",
    "    rho0 : numpy.ndarray\n",
    "        The initial density matrix.\n",
    "    ops : list of numpy.ndarray\n",
    "        List of operators for which expectation values are computed.\n",
    "    dt : float\n",
    "        The time step size.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    obs : numpy.ndarray\n",
    "        The expectation values of the operators over time.\n",
    "    rhot : numpy.ndarray\n",
    "        The final density matrix.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> H0 = np.array([[1, 0], [0, -1]])\n",
    "    >>> H1 = np.array([[0, 1], [1, 0]])\n",
    "    >>> u = np.array([0.1, 0.2, 0.3])\n",
    "    >>> rho0 = np.array([[1, 0], [0, 0]])\n",
    "    >>> ops = [np.array([[1, 0], [0, 1]]), np.array([[0, 1], [1, 0]])]\n",
    "    >>> dt = 0.01\n",
    "\n",
    "    # Compute the expectation values and final density matrix\n",
    "    >>> obs, rhot = expvalsPiecewiseConstHt(H0, H1, u, rho0, ops, dt)\n",
    "    >>> obs\n",
    "    array([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
    "       [1.99993267e-05, 9.99883939e-05, 2.79931701e-04]])\n",
    "    >>> rhot\n",
    "    array([[9.99964010e-01+1.73472348e-18j, 1.39965851e-04+5.99745641e-03j],\n",
    "       [1.39965851e-04-5.99745641e-03j, 3.59903691e-05+0.00000000e+00j]])\n",
    "    \"\"\"\n",
    "\n",
    "    nr_steps = len(u)\n",
    "\n",
    "    obs = np.zeros((len(ops),nr_steps))\n",
    "    rhot = rho0\n",
    "    for i in range(nr_steps):\n",
    "        Hi = H0 + u[i] * H1\n",
    "        Ui = linalg.expm(-1j*dt*Hi)\n",
    "        rhot = Ui @ rhot @ Ui.T.conjugate()\n",
    "        for s in range(len(ops)):\n",
    "            obs[s,i] = np.real(np.trace(ops[s] @ rhot))\n",
    "                \n",
    "    return obs, rhot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp(iθn⋅σ) = cosθ I+i(n⋅σ)sinθ\n",
    "# exp(-iudt Sx) = exp(-iudt/2 σx) = cos(udt/2) I - iσx sin(udt/2)\n",
    "def expm_trotter_H1x(expiA, b1, u, ds, nr_halvings):\n",
    "    \"\"\"Returns the approximate exponential of a Hamiltonian.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expiA : numpy.ndarray\n",
    "        The exponential of the A Hamiltonian.\n",
    "    b1 : XXX\n",
    "        xxx\n",
    "    u : numpy.ndarray\n",
    "        The magnetic field (dependent variable)\n",
    "    ds : int\n",
    "        Time step size.\n",
    "    nr_halvings : int\n",
    "        The number of halvings.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    U : numpy.ndarray\n",
    "        The approximate exponential of the Hamiltonian.\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> expiA = np.eye(4)\n",
    "    >>> b1 = 0.1\n",
    "    >>> u = 0.1\n",
    "    >>> ds = 0.01\n",
    "    >>> nr_halvings = 3\n",
    "\n",
    "    # Compute the approximate exponential of the Hamiltonian\n",
    "    >>> U = expm_trotter_H1x(expiA, b1, u, ds, nr_halvings)\n",
    "    \"\"\"\n",
    "\n",
    "    dim_n = expiA.shape[0]//4\n",
    "    omega = b1*u*ds/2\n",
    "    c = np.cos(omega)\n",
    "    s = -1j * np.sin(omega)\n",
    "    expiB_1 = np.array([[c,s],[s,c]])\n",
    "    dexpiB_1 = (-1j*ds*b1/2) * np.array([[s,c],[c,s]])\n",
    "    expiB_12 = np.kron(expiB_1, expiB_1)\n",
    "    dexpiB_12 = np.kron(dexpiB_1, expiB_1) + np.kron(expiB_1, dexpiB_1)\n",
    "    # expiB = sparse.kron(expiB_12, sparse.eye(dim_n, format=\"csr\"))\n",
    "    # dexpiB = sparse.kron(dexpiB_12, sparse.eye(dim_n, format=\"csr\"))\n",
    "    # expiB = sparse.kron(sparse.csr_matrix(expiB_12), qt.fastsparse.fast_identity(dim_n))\n",
    "    # dexpiB = sparse.kron(sparse.csr_matrix(dexpiB_12), qt.fastsparse.fast_identity(dim_n))\n",
    "    expiB = np.kron(expiB_12, np.eye(dim_n))\n",
    "    dexpiB = np.kron(dexpiB_12, np.eye(dim_n))\n",
    "    U = expiA @ (expiB @ expiA)\n",
    "    L = expiA @ (dexpiB @ expiA)\n",
    "    for i in range(nr_halvings, 0, -1):\n",
    "        L = U @ L + L @ U\n",
    "        U = U @ U\n",
    "    return U"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient functions Eduardo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expvalGradMultiSamples2(H0, H1, u, rho0, op, dt, w):\n",
    "    \n",
    "    nr_samples = len(w)\n",
    "    nr_steps = len(u)\n",
    "#    assert(np.mod(nr_steps, nr_samples) == 0)\n",
    "    nr_substeps = nr_steps//nr_samples\n",
    "    \n",
    "    U_list = []\n",
    "    for i in range(nr_steps):\n",
    "        Hi = H0 + u[i] * H1\n",
    "        Ui, _ = linalg.expm_frechet(-1j*dt*Hi, -1j*dt*H1) #GRADIENT HERE\n",
    "        U_list.append(Ui)\n",
    "        \n",
    "    obs = 0.0\n",
    "        \n",
    "    Uf = np.eye(H0.shape[0]) # after loop: UnUn-1...U1U0\n",
    "#    dUUf_list = [] # GRADIENT HERE\n",
    "#    Ub_list = []   # GRADIENT HERE\n",
    "    for j in range(nr_samples):\n",
    "        m = j * nr_substeps\n",
    "        n = m + nr_substeps\n",
    "        Ub_list_j = []\n",
    "        Ub = np.eye(H0.shape[0]) # after loop: UnUn-1...Um\n",
    "        for i in range(nr_substeps):\n",
    "            Ui = U_list[i + m] #GRADIENT HERE?\n",
    "#            dUUf_list.append(dUi @ Uf) #GRADIENT HERE?\n",
    "            Uf = Ui @ Uf\n",
    "            Ub_list_j.insert(0, Ub) #GRADIENT HERE?\n",
    "            Ub = Ub @ U_list[n-1-i][0]\n",
    "#        for i in range(len(Ub_list)):\n",
    "#            Ub_list[i] = Ub @ Ub_list[i]\n",
    "#        Ub_list = Ub_list + Ub_list_j\n",
    "        A = rho0 @ Uf.T.conjugate() \n",
    "        #print(A.shape)\n",
    "        B = A @ op\n",
    "        BT = B.T\n",
    "        # obs += w[j] * np.real(np.trace(Uf @ B))\n",
    "        obs += w[j] * np.real(np.sum(Uf.__mul__(BT)))\n",
    "            \n",
    "    rhot = Uf @ A\n",
    "        \n",
    "    return obs, Uf\n",
    "\n",
    "\n",
    "def expvalGradMultiSamplesSplitTrotterH1x2(H0, b1, u, rho0, op, dt, w, nr_halvings=4):\n",
    "    \n",
    "    nr_samples = len(w)\n",
    "    nr_steps = len(u)\n",
    "#    assert(np.mod(nr_steps, nr_samples) == 0)\n",
    "    nr_substeps = nr_steps//nr_samples\n",
    "    \n",
    "    dim = rho0.shape[0]\n",
    "    \n",
    "    ds = dt / 2**nr_halvings\n",
    "    UA = linalg.expm(-1j*ds/2*H0) \n",
    "    \n",
    "    U_list = []\n",
    "    for i in range(nr_steps):\n",
    "        # Hi = H0 + u[i] * H1 \n",
    "        # Ui, dUi = linalg.expm_frechet(-1j*dt*Hi, -1j*dt*H1)\n",
    "        Ui, _ = expm_trotter_H1x(UA, b1, u[i], ds, nr_halvings)\n",
    "        U_list.append((Ui,dUi))\n",
    "        \n",
    "    obs = 0.0\n",
    "        \n",
    "    Uf = np.eye(dim) # after loop: UnUn-1...U1U0\n",
    "#    dUUf_list = [] # [dU0, dU1U0, dU2U1U0, dU3U2U1U0, ..., dUnUn-1...U1U0] #GRADIENT HERE\n",
    "    Ub_list = []   # [Un...U2U1, Un...U2, ..., UnUn-1Un-2, UnUn-1, Un, 1] #GRADIENT HERE\n",
    "    for j in range(nr_samples):\n",
    "        m = j * nr_substeps\n",
    "        n = m + nr_substeps\n",
    "        Ub_list_j = []\n",
    "        Ub = np.eye(dim) # after loop: UnUn-1...Um\n",
    "        for i in range(nr_substeps):\n",
    "            Ui, dUi = U_list[i + m]\n",
    "#            dUUf_list.append(dUi @ Uf) #GRADIENT HERE\n",
    "            Uf = Ui @ Uf\n",
    "            Ub_list_j.insert(0, Ub)\n",
    "            Ub = Ub @ U_list[n-1-i][0]\n",
    "        for i in range(len(Ub_list)):\n",
    "            Ub_list[i] = Ub @ Ub_list[i]\n",
    "        Ub_list = Ub_list + Ub_list_j\n",
    "        A = rho0 @ Uf.T.conjugate()\n",
    "        #print(A.shape)\n",
    "        B = A @ op\n",
    "        BT = B.T\n",
    "        # obs += w[j] * np.real(np.trace(Uf @ B))\n",
    "        obs += w[j] * np.real(np.sum(Uf.__mul__(BT)))\n",
    "        \n",
    "            \n",
    "    rhot = Uf @ A\n",
    "        \n",
    "    return obs, Uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun2(u, H0, H1, rho0, obs, dt, w, minimize):\n",
    "    if type(H1) == float:\n",
    "        ys,_ = expvalGradMultiSamplesSplitTrotterH1x2(H0, H1, u, rho0, obs, dt, w)\n",
    "    else:\n",
    "        ys,_ = expvalGradMultiSamples2(H0, H1, u, rho0, obs, dt, w)\n",
    "    if not minimize:\n",
    "        ys = -ys\n",
    "        #grad = -grad\n",
    "           \n",
    "    return ys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at a generalisation of the system studied in this paper: https://aip.scitation.org/doi/abs/10.1063/1.5131557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkSystem(b0, b1, kS, k0):\n",
    "\n",
    "    g = 2.00231930436256 #electron g-factor\n",
    "    beta = 9.274009994e-24 #bohr magneton\n",
    "    hbar = 6.62607015e-34/(2*np.pi) #hbar\n",
    "    mT = g*beta/hbar*1e-9 # mT -> Mrad/s\n",
    "\n",
    "    omega0 = b0*mT\n",
    "    omega1 = b1*mT\n",
    "    Is = [0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "    indE = [0, 0, 0, 1, 1]\n",
    "    hfcs = np.array([0.2, 0.5, 1.0, 0.2, 0.3]) * mT # mT -> Mrad/s\n",
    "    jex = 1 * 2*math.pi\n",
    "\n",
    "    dims = [2, 2] + [round(2*Is[i]+1) for i in range(len(Is))]\n",
    "    Hhfc = sum(mkH12(dims, indE[i], i+2, np.eye(3)*hfcs[i]) for i in range(len(hfcs)))\n",
    "    Hzee = mkH1(dims, 0, [0,0,omega0]) + mkH1(dims, 1, [0,0,omega0])\n",
    "    Hex = -jex * (1/2*mkSpinOp(dims, []) + mkH12(dims, 0, 1, 2*np.identity(3)))\n",
    "    H0 = Hhfc + Hzee + Hex\n",
    "    H1 = mkH1(dims, 0, [omega1,0,0]) + mkH1(dims, 1, [omega1,0,0])\n",
    "    Ps = 0.25 * mkSpinOp(dims,[]) - mkH12(dims, 0, 1, np.eye(3))\n",
    "    H = H0 - 1j * kS/2 * Ps\n",
    "    rho0 = Ps/Ps.tr()\n",
    "    H, H1, rho0 = [dense(op) for op in (H, H1, rho0)]\n",
    "    Ps = Ps.data\n",
    "\n",
    "    sys = {\n",
    "        'Is': Is,\n",
    "        'indE': indE,\n",
    "        'hfcs': hfcs,\n",
    "        'jex': jex,\n",
    "        'omega0': omega0,\n",
    "        'omega1': omega1,\n",
    "        'kS': kS,\n",
    "        'k0': k0\n",
    "    }\n",
    "\n",
    "    return H, H1, omega1, rho0, Ps, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeYield(name, b0, b1, kS, k0, nr_cycles, nr_steps, nr_samples, eda_opt):\n",
    "\n",
    "    # Optimize singlet probability after nr_steps steps of dt usind L-BFGS-B\n",
    "\n",
    "    dt = 0.001\n",
    "    nr_total = max(math.ceil(5/k0) * 1000, nr_cycles*nr_steps)\n",
    "    nr_iter = 200\n",
    "    minimize = True\n",
    "\n",
    "    t_sampled = (np.arange(nr_samples) + 1) * (nr_steps//nr_samples)*dt # without t0\n",
    "    # w = np.ones(nr_samples)\n",
    "    w = np.exp(-t_sampled*k0) * k0 * (nr_steps//nr_samples)*dt\n",
    "\n",
    "    H, H1, omega1, rho0, Ps, sys = mkSystem(b0, b1, kS, k0)\n",
    "\n",
    "    rho = rho0\n",
    "    \n",
    "    #stats = []\n",
    "    uopt_all = []\n",
    "    for i in range(nr_cycles):\n",
    "        u0 = np.random.randn(nr_steps)\n",
    "        ind = np.where(np.abs(u0) > 1)[0]\n",
    "        u0[ind] = np.sign(u0[ind])\n",
    "        \n",
    "        if eda_opt:\n",
    "            eda = UMDAd(size_gen=30, max_iter=100, dead_iter=10, n_variables=8, alpha=0.5, vector=None,\n",
    "            lower_bound=0.2, upper_bound=0.9, elite_factor=0.2, disp=True)\n",
    "\n",
    "            eda_result = eda.minimize(cost_function=fun2(u0, H, H1, rho0, obs, dt, w, minimize), output_runtime=True)\n",
    "            \n",
    "            \"\"\"\n",
    "            CHANGE THIS LINE ABOVE WITH THE CORRECT OBS!!!!!\n",
    "            \"\"\"\n",
    "            \n",
    "            #eda_result = eda.minimize(cost_function=fun2(u0, H, H1, rho0, obs = np.eye(128), dt, w, minimize),\n",
    "            #                          output_runtime= True)\n",
    "        else:\n",
    "            opt = optimize.minimize(fun, u0, \n",
    "                        args=(H, omega1, rho, Ps, dt, w, minimize),\n",
    "                        method='L-BFGS-B',\n",
    "                        jac=True, bounds=[(-1,1) for _ in range(len(u0))],\n",
    "                        options={'disp': 0, 'maxcor': 60, 'ftol': 1e-6, 'gtol': 1e-7, 'maxiter': nr_iter})\n",
    "            print(opt.message)\n",
    "            print(opt.fun)\n",
    "        \n",
    "        \n",
    "        u = opt.x\n",
    "        uopt_all.append(u)\n",
    "        #stats.append((opt.fun, opt.nit, opt.nfev, opt.success))\n",
    "        \n",
    "        ps, rho = expvalsPiecewiseConstHt(H, H1, u, rho, [Ps], dt)\n",
    "        \n",
    "    u = np.concatenate(uopt_all)\n",
    "    u = np.concatenate((u, np.zeros(nr_total-len(u))))\n",
    "    t = np.arange(len(u))*dt\n",
    "    ps, _ = expvalsPiecewiseConstHt(H, H1, u, rho0, [Ps], dt)\n",
    "    ps = ps[0]\n",
    "    ys = integrate.simps(ps*k0*np.exp(-k0*t))*dt\n",
    "    ps0, _ = expvalsConstH(H, rho0, [Ps], dt, nr_total)\n",
    "    ps0 = ps0[0]\n",
    "    ys0 = integrate.simps(ps0*k0*np.exp(-k0*t))*dt\n",
    "    print(\"{} x {} @ {} : {} vs. {}\".format(nr_cycles, nr_steps, nr_samples, ys, ys0))\n",
    "    \n",
    "    np.savez(name, sys=sys, u=u, \n",
    "             nr_cycles=nr_cycles, nr_steps=nr_steps, nr_samples=nr_samples, nr_iter=nr_iter, minimize=minimize,\n",
    "             ys=ys, ys0=ys0, ps=ps, ps0=ps0) #stats=stats)\n",
    "\n",
    "    return ys, ps #, stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we train normally! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cycles = 1       # number of cycles\n",
    "nr_steps = 1000     # number of steps\n",
    "dt = 0.001          # time step\n",
    "nr_samples = 100    # number of samples\n",
    "\n",
    "b0 = 0.05 # mT (this is the geomagnetic field, relavant to avian magnetoreception)\n",
    "b1 = 0.25 # mT, free to try different parameters here\n",
    "k0 = 1.0 # 1/us\n",
    "kS = 1.0 # 1/us\n",
    "\n",
    "nr_total = max(math.ceil(5/k0) * 1000, nr_cycles*nr_steps)\n",
    "nr_iter = 200\n",
    "minimize = True     # are we using minimalization or maximalization function?\n",
    "\n",
    "t_sampled = (np.arange(nr_samples) + 1) * (nr_steps//nr_samples)*dt # without t0\n",
    "# w = np.ones(nr_samples)\n",
    "w = np.exp(-t_sampled*k0) * k0 * (nr_steps//nr_samples)*dt\n",
    "\n",
    "H, H1, omega1, rho0, Ps, sys = mkSystem(b0, b1, kS, k0)\n",
    "\n",
    "rho = rho0\n",
    "\n",
    "#obs = np.eye(128,128)\n",
    "obs = Ps\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    u0 = np.random.randn(100)\n",
    "    ind = np.where(np.abs(u0) > 1)[0]\n",
    "    u0[ind] = np.sign(u0[ind])\n",
    "\n",
    "args = (H, H1, rho0, obs, dt, w, minimize)\n",
    "fun2(u0, *args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim1, hidden_dim2, action_dim):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        actions = self.fc3(x)\n",
    "        return actions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, gamma, epsilon, tau, lr, state_dim, hidden_dim1, hidden_dim2, action_dim, device):\n",
    "        self.device = device\n",
    "        self.gamma = gamma  # discount fator\n",
    "        self.epsilon = epsilon  # exploration rate\n",
    "        self.tau = tau # target network update frequency\n",
    "        self.lr = lr # learning rate\n",
    "        self.action_dim = action_dim\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.q_net = Network(state_dim, hidden_dim1, hidden_dim2, action_dim).to(self.device) # policy network\n",
    "        self.target_q_net = Network(state_dim, hidden_dim1, hidden_dim2, action_dim).to(self.device) # target network\n",
    "        self.optimizer = optim.Adam(self.q_net.parameters(), lr=self.lr)\n",
    "        self.count = 0\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        store (state, action, reward, next_state) for experience replay\n",
    "        \"\"\"\n",
    "        self.memory.append((state, action, reward, next_state)) \n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        sample (state, action, reward, next_state) from memory\n",
    "        \"\"\"\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states = zip(*samples)\n",
    "        return np.array(states), np.array(actions), np.array(rewards), np.array(next_states)\n",
    "\n",
    "    def take_action(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.randint(self.action_dim)\n",
    "        else:\n",
    "            state = T.tensor([state], dtype=T.float).to(self.device)\n",
    "            action = self.q_net(state).argmax().item()\n",
    "        return action\n",
    "\n",
    "    def update(self, states, actions, rewards, next_states, done):\n",
    "        \"\"\"\n",
    "        update the target network\n",
    "        \"\"\"\n",
    "        states = T.tensor(states, dtype=T.float).to(self.device)\n",
    "        actions = T.tensor(actions).view(-1, 1).to(self.device)\n",
    "        rewards = T.tensor(rewards, dtype=T.float).view(-1, 1).to(self.device)\n",
    "        next_states = T.tensor(next_states, dtype=T.float).to(self.device)\n",
    "\n",
    "        q = self.q_net(states).gather(1, actions)  # Q-value\n",
    "        next_q = self.target_q_net(next_states).max(1)[0].view(-1, 1) # max Q-value of the next state\n",
    "        q_targets = rewards + self.gamma * next_q * (1 - done) # expected Q-value\n",
    "        loss = T.mean(F.mse_loss(q, q_targets))\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        if self.count % self.tau == 0:\n",
    "            self.target_q_net.load_state_dict(self.q_net.state_dict())\n",
    "        self.count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 50\n",
    "gamma = 0.95\n",
    "epsilon = 0.01\n",
    "tau = 10\n",
    "lr = 1e-3\n",
    "state_dim = 100\n",
    "hidden_dim1 = 64\n",
    "hidden_dim2 = 64\n",
    "action_dim = 21\n",
    "batch_size = 48\n",
    "device = T.device(\"cuda\") if T.cuda.is_available() else T.device(\"cpu\")\n",
    "agent = Agent(gamma, epsilon, tau, lr, state_dim, hidden_dim1, hidden_dim2, action_dim, device)\n",
    "\n",
    "episode_list = []\n",
    "yield_list = []\n",
    "state_list = []\n",
    "for e in tqdm(range(num_episodes), desc=\"Main\", leave=True):\n",
    "    state = np.zeros(state_dim)\n",
    "    episode_return = 0\n",
    "    for s in tqdm(range(state_dim), desc=\"loop for e = {}\".format(e), leave=False):\n",
    "        action = agent.take_action(state)\n",
    "        next_state = state\n",
    "        for i in range(s, state_dim):\n",
    "            next_state[i] = 0.1 * action - 1\n",
    "        reward = -1 * fun2(next_state, *args)\n",
    "        agent.memorize(state, action, reward, next_state)\n",
    "        state = next_state\n",
    "        episode_return += reward\n",
    "        if len(agent.memory) > batch_size:\n",
    "            states, actions, rewards, next_states = agent.sample(batch_size)\n",
    "            done = True if s == state_dim-1 else False\n",
    "            agent.update(states, actions, rewards, next_states, done)\n",
    "    e_yield = fun2(state, *args)\n",
    "    print(\"episode: {}/{}, score: {}, yield: {}\".format(e+1, num_episodes, episode_return, e_yield))\n",
    "    episode_list.append(episode_return)\n",
    "    yield_list.append(e_yield)\n",
    "    state_list.append(state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final obtained magnetic field pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "sns.lineplot(x=range(len(yield_list)), y=yield_list, marker = \"o\", markersize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
